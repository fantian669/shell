sort:
   作用:排序文件,对已排序的文件进行合并,并检查文件以确定它们已排序

uniq:
   作用:报告或删除文件中重复的行

wc:
   作用:提供文本的行数,字数,字符数统计

pr:
   作用:向标准输出写文件


fmt:
   作用:从指定文件里读取内容,将其按照指定格式重新编排后,输出到标准设备.如果指定的文件名为"-"则fmt指令会从标准输入设备中读取数据


fold:
   作用:折叠有限宽度的输出设备的长行过滤器 限制文本宽度


head:
   作用:显示一个或多个文件的前几行或前几个字符

cut:
   作用:从文件的每个行中写出选定的字节,字符或字段

join:
   作用:连接两个文件的数据字符

tr:
   作用:从标准输入删除或替换字符,并将结果写入标准输出


eg1:
   在某个大型网站的服务器每天数以亿计的访问者 访问记录中包含两个字段
访问者ip,访问者id,访问时间

10:20     202.114.112.5     3211245
10:21     210.120.56.3      3210221

(1) 分析哪些ip的访问异常,例如出现段时间内大量访问情况(可能是用机器人登录的结果)
(2) 分析哪些用户为活跃用户
(3) 分析哪些用户的账户存在异常(例如,一瞬间切换ip)


如何判断ip短时间内出现大量请求 因为一个连接请求一条记录,每天读取ip访问次数最高的的前100名



使用cut 取出ip和id字段
cat record.txt

显示:

10:20  201.12.54.6  321125
10:21  210.103.1.65 325641
10:22  201.124.12.42 123462
10:23  199.12.11.45  124578
10:24  110.45.56.12  568941

使用cut命令 -d  接收字段分隔符
cut -d " " -f 2,3 record.txt
显示:

201.12.54.6  321125
210.103.1.65 325641
201.124.12.42 123462
199.12.11.45  124578
110.45.56.12  568941

使用sort排序 以字典序排序 将ip字典序排序

cut -d " " -f 2,3 record.txt | sort

使用uniq统计重复ip

cut -d " " -f 2,3 record.txt | sort | uniq -c


如果不使用 sort排序 直接使用uniq 可能会出现相同记录不会合并 
因为uniq 在去重时并不会考虑相同记录隔很远的情况



   再次 根据访问次数排序  不过使用次数 进行倒序排列

sort -r



   提出出现次数最多的前100条记录 使用head 命令


最终命令:

	 cut -d " " -f 2,3 record.txt |sort|uniq -c |sort -r | head -n 100

这样就获取当天访问ip最多的前100条 






















